	2.1概述
	
	
	屏幕剪辑的捕获时间: 2024/10/22 20:13
		cuda特有功能：线程层次、内存层次
		并行计算：
			领域层：解析数据和数据
			逻辑层：正确解决问题=》线程和计算
			硬件层：理解线程映射以帮助提高性能
	2.1.1
		主机内存、设备内存：PCIE
		内存拷贝方式经过几次演变：cuda6.0同一寻址已经可以避免拷贝，但是我们还要学拷贝，这样硬件利用率更大
	2.1.2内存管理
		cudaMalloc、cudaMemcpy（可以指定方向，阻塞方式进行）
		cudaGetErrorString：获取错误信息
		Gpu共享内存、全局内存
		
		
		
		屏幕剪辑的捕获时间: 2024/10/22 20:29
		一旦 内核被调用，控制权立刻被传回主机，这样的话，当核函数在GPU上运行时，主机可以执 行其他函数。因此，内核与主机是异步的
		统一寻址的原理
	2.1.3 线程管理
		线程网格中含有多个线程块、线程块block中含有多个线程
		线程网格：一个内核启动所产生的所有线程，同一网格中所有线程共享相同的全局内存
	
	
	屏幕剪辑的捕获时间: 2024/10/24 20:12
		block中线程协作：同步、共享内存
		不同block的线程不能协作
		线程区分：blockId、threadIdx（块内）
		网格、block、thread都可以有多维度
		通常：二维block组成网格、三维线程组组成block
		线程格和线程块：主机端是dim3类型，设备段是unit类型
			通常流程：定义block大小（线程个数），网格大小是块大小的倍数
				主机段：block、grid 设备端：blockdim、griddim
			Block/blockdim： 每个维度上的线程数量 blockIdx：grid中的blockIdx
			Grid/griddim： 每个维度上的block数量 对一个任务来说，grid只有一个
			如此理解：blockDim代表某个维度线程的多少，griddim代表某个维度block的多少
			确定块的尺寸：内核性能特性、GPU资源限制
		因为主机和设备异步，可以通过cudaDeviceSynchronize来进行同步，有些cuda版本会隐式同步
		
	2.1.5 编写核函数
		__global__ 、 __device__、__host__
		核函数限制：只能访问设备内存、返回void、不支持可变数量参数、不支持静态变量、显示异步行为
		每个线程要用的数据要指定明白
	2.1.6 验证核函数
	2.1.7处理错误
		使用错误处理宏封装所有cuda api：会阻塞主机进程，仅用于调试
2.2 给核函数计时
	2.2.1使用cpu计时器
		Gettimeofday
	2.2.2 nvprof
		用于统计执行时间，分析数据传输和核函数执行所用时间
		指令：字节，也就是运算峰值次数：数据传输次数；如果超过这个比例，运算就会受限；
2.3组织并行线程
	三种索引：线程和块索引、矩阵定点坐标、全局线性内存偏移量
		1、线程/块 索引到矩阵坐标；
		2、使用矩阵坐标映射到全局存储索引
		printThreadInfo函数呗用于输出每个线程的：线程/块索引、矩阵坐标、内存偏移、值
	2.3.2 二维求和/一维求和/二网一块：不同配置性能差异巨大
	
	
	
	屏幕剪辑的捕获时间: 2024/11/6 21:00
2.4 设备管理
	打印设备信息：cudaGetDeviceProperties
	2.4.2确定最优GPU：就是获取GPU处理器个数然后进行比较
	Nvidia-smi查询GPU信息：
