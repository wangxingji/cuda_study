	3.1.1gpu架构概述
		SM关键组件：cuda核心、共享内存/一级缓存、寄存器文件、访存单元、特殊单元、线程束调度器
		调度是基于线程块做的，线程块和SM是n-1的关系
		warp：32个线程成为一个线程束（对应硬件资源SM），可以发现，一个block可能分成好几个线程束执行，但是多个block不可能在同一个线程束，因为线程束内指令都相同
		SIMT相比SIMD：每个线程自己的指令地址计数器、寄存器状态、独立执行路径，但他们实际还是同步的，只不过颗粒比SIMD小
		同一时间，一个SM可以容纳多个线程块？是的，一个阻塞可以上另一个
		
		
		线程块内的线程逻辑并行，并非物理并行？因为一个块只能在一个SM，同一时间最多调用32个线程，因此不可能物理并行；warp内的线程才是物理并行？好像并不，因为load/st单元不一定32个
		线程块内的线程通过共享内存进行合作
		cuda提供线程块内的线程同步方法，但不提供块间的；
		在并发的线程束之间切换没有开销，因为硬件资源已经分配到了线程和块中，不存在切换上下文的事
		SM上可以有多个warp同时跑吗？依赖特定架构？
		SFU:特殊功能单元
		Fermi架构：表现得更像MIMD
			每个SM 32个核心，分成两组，对应两组线程束调度器/指令分派单元
			两个调度器选则两个线程束，再把指令发送到其中一个组上，这里一个warp内的32个线程并不能同时执行，一次只能执行16个？
			可以同时处理48个线程束，也就是1536个线程，显然这些线程会存在切换
		Kepler架构：
			每个SM 192个核、64个双精度、32个SFU、32个访存 4个线程束调度器 8个指令调度器
				单SM同时执行4个线程束 同时调度 64个线程束，即2048个线程
			keper新特性：动态并行，其实就事GPU的核客气启动核
			Fermi CPU-GPU只有一个硬件队列，kerper有32个
	3.1.4 配置文件驱动优化
		事件（计数器）
		指标
		存储带宽、计算资源、指令和内存延时
		线程束内线程执行相同的指令，如果出现分支，则禁用不同分支的计算，叫做线程束分化
			分化后被禁用的何时执行？进if则then停止，进then则if停止
		内核分化计数：
			Nvprof -metrics efficiency ./xxx
		内核分化事件计数：
			Nvprof -events branch,divergent_branch ./xxx
		SM可以跑多少warp不受限于核数量，主要受限制于寄存器 / 共享内存？
		计算资源分配给线程块，为活越线程块，其中为活越线程束
		活越线程束三类：选定、阻塞、符合条件
		warp执行条件：参数就绪，有三个空闲核
		最大活越线程数：线程提前分好了资源，所以上下文切换没有损耗，但也就要求资源够多，在资源有限时线程活越尽可能多
	3.2.4 延迟隐藏
		指令类型：算术指令、内存指令
		算数延迟：10到20周期  内存延迟：400~800周期
			在这些间隙，可以插入其他warp执行，其实就是指令并发那套东西
			隐藏延迟需要的活跃线程束数量计算-科特尔法则提供一个近似值： 线程数量 = 延迟 X 吞吐量
				每个周期吞吐6个warp，平均延时5周期，则需要30个活越warp
			带宽是理论值，用于数据传输
			而吞吐量是已达到的值，用于数据传输/执行速度
		两种并行：指令级并行、线程级并行
			每个线程创建更多的内存操作，就可以增加并行 
	3.2.5 占有率
		核使用寄存器控制：-maxrregcount=NUM
		为了提高占有率，需要调整线程块配置或重新调整资源使用情况以增加活越线程
			小线程块：
			大线程块：单个线程资源太少
			准则：
				块中线程数是32倍数
				避免块太小，至少128或256
				根据内核资源调整块大小
				块的数量要远远多于SM
				实验
